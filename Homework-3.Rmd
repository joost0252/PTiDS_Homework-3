---
title: "homework-3"
author: "Amina Mohammed (17301920), Joost Dijkstra (2095148183),Edward Tandia (17310806)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r, echo = FALSE, include = FALSE, message = FALSE}
source(here::here("Setup.R"))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Problem statement

The bootstrap is a straightforward method for estimating quantities for a statistic such as an estimator of its variance. 


#### Exercise Solving


1. Using your most efficient implementation of the bootstrap from the previous homework, write a function named `bootstrap` with arguments `x` for a vector of sample data, `B` for the number of bootstrapped samples with default values `1000L` and `statistic` for a generic function to be passed. The function must return a list with the statistic evaluated on the sample `x`, say `theta_hat`, on the bootstrapped samples, say `theta_star`, and an estimate of the variance of the statistic, say `varBoot`.

```{r echo = FALSE, include = FALSE, message = FALSE}

#turn on set.seed() if you want the results not to vary
set.seed(626)

B = 1000L                                  #  Number of bootstrapped samples with default values 1000L
Statistic <- as.data.frame(matrix(c("var", "mean")))
var <- Statistic[1,1]
mean <- Statistic[2,1]

# Bootstrap with a for loop 
 
  
Bootstrap <- function(data, B, Statistic) {
  thêta_hat<- rep(0,B)
  thêta_star <- rep(0,B)
  
  
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
}
```

My most efficient implementation of the bootstrap from the previous homework was the for loop. Based on this, I create function with 3 input: <i> data, B, Statistic </i>. <br>

- <i> data </i>: is the data input <br>
- <i> B </i>: is the number of bootstrapped samples with default values <br>
- <i> Statistic </i>: is the statistcic which the user can selected. It has to be a function; either mean or variance. <br>

the function `Bootstrap` will return 3 output: <i> theta_hat, theta_star, varBoot </i>

- <i> theta_hat </i>: is a list with the statistic evaluated on the sample <br>
- <i> theta_star </i>: is a list with the statistic on the bootstrapped samples<br>
- <i> varBoot </i>: is the estimate of the variance of the statistic. <br>

I used for loops and multiple if conditioning in order to build my function.

<br>

2.  Simulate a sample of size $10^4$ from a $t$-distribution with $\nu=3$ degrees of freedom (when $\nu\to\infty$, then the $t$-distribution tends to a standard normal distribution). Using the base R variance `var` as the `statistic`, compute the $B=1,000$ bootstrapped statistics using your function for subsamples of size $100$, $1,000$ and the full sample that you generated, and make three boxplots in one graph. The true variance is given by $\nu/(\nu-2)$. Illustrate it in your graph and comment what has been obtained. Does it illustrate some concepts in statistics or probability theory?

```{r echo = FALSE, include = FALSE, message = FALSE}

# for the sample of size $10^4$ from a $t$-distribution with $\nu=3$ degrees of freedom

samplesize <- 1:10^4                                                    #size of the sample
mydata <- dt(samplesize, df = 3)                                        # data we will boostrap 

# Bootstraping in full sample
full_sample <- Bootstrap(data = mydata, B = 1000L, Statistic = var)

plot_full <- ggplot(as.data.frame(full_sample), aes(y=thêta_hat)) + 
  geom_boxplot(notch=TRUE) 
#+ 
  #geom_hline(yintercept = full_sample$varBoot)
#+ geom_hline(yintercept=true_variance, color= "red")

# Subsample for size 100

Subsample_100 <- dt((mydata[1:100]), df = 3)   
boostrap_Subsample_100 <- Bootstrap(data = Subsample_100, B = 1000L, Statistic = var)
plot_100 <- ggplot(as.data.frame(boostrap_Subsample_100), aes(y=thêta_hat)) + 
  geom_boxplot(notch=TRUE) 
#+ geom_hline(yintercept=true_variance, color= "red")

# Subsample for size 1000

Subsample_1000 <- dt(mydata[1:1000], df = 3)   
boostrap_Subsample_1000 <- Bootstrap(data = Subsample_1000, B = 1000L, Statistic = var)
plot_1000 <- ggplot(as.data.frame(boostrap_Subsample_1000), aes(y=thêta_hat)) + 
  geom_boxplot(notch=TRUE) 
#+ geom_hline(yintercept=true_variance, color= "red")

# Compute the true variance
v <- (3)
true_variance <- (v / (v-2))

library(ggplot2)
library(gridExtra)

```

I have simulate a sample of size $10^4$ from a $t$-distribution with $\nu=3$ degrees of freedom. I have run 3 different boostraps using variance `var` as the `statistic`, for the following subsamples of size $100$, $1,000$  with  $B=1,000$. You can see the four boxplots.

When we compare the output with the true variance, which is given by $\nu/(\nu-2)$ = `r true_variance`. We can observe that `r true_variance`  is really high compare to the `r `varboot`. 

Does it illustrate some concepts in statistics or probability theory? *ANSWER TO IT*

<br>

```{r, message = FALSE}
grid.arrange(plot_full, plot_100,plot_1000,  nrow = 1)
```

3.  Take the one of the subsample of 2., and compare the performances between your implementation of `bootstrap` with the function bootstrap from the bootstrap package (installation required). Make sure the comparison is as fair as possible (same number of bootstrap samples, ...).

In order to compare the performance of our implementation of `Bootstrap` we build to the function bootstrap from the bootstrap package. In order to make it as fair as possible, I'm going to take the subsample $1,000$ to have same number of bootstrap samples. Furthermore, I apply the same statistic to have also the same basis. 

Note that I tried to use the subsample $100$, <i> Profvis produces error : No parsing data available. Maybe your function was too fast? </i> Thus I  increase the subsample to $1,000$ to make the computation longer.

```{r, message = FALSE, warning=FALSE}
#compare the performances 
set.seed(626)
profvis::profvis({
  # Profiling boostrap_Subsample_100
  
Subsample_1000 <- dt(mydata[1:1000], df = 3)     
boostrap_Subsample_1000 <- Bootstrap(data = Subsample_1000, B = 1000L, Statistic = var)

  })
```

```{r, message = FALSE}
set.seed(626)
profvis::profvis({
  # Profiling Bootstrap with bootstrap package from R boostrap_Subsample_100
Subsample_1000 <- dt(mydata[1:1000], df = 3)    
boot_Subsample_1000 <- boot(Subsample_1000, statistic = var, R=1000L)
  })
```

<br>
<br>

Thus, the memory usage and computation time for the Bootstrap **using my function** are : <br>
-Memory usage : 27 MB <br>
-Computation time: 810 (ms) <br>

And the memory usage and computation time for Bootstrap **using the function from R** are: <br>
-Memory usage : 0 MB <br>
-Computation time : 20 (ms) <br>

Based on the profiling, we can see that the the computation time using my function is much higher that the case of using the function from R, however, these 2 functions are hardly comparable even though we use the same data as an input. 

Indeed, `boot` from R package can return error, warning and different other messages, it is optimize and perfom much more than my computation. Theses different implementations increase the time of computing. 
<br>
<br>

4.  Load `test1.rds` and make this call `bootstrap(a, statistic = mean)`. The call must returns the following error: Error in bootstrap(a, statistic = mean) : 'x' must be numeric

```{r echo = FALSE, include = FALSE, message = FALSE}

library(rstan)
test1 <- readRDS("test1.rds")
typeof(test1)
call(test1)

a <- test1

```

```{r echo = FALSE, include = FALSE, message = FALSE}
# add to Error and Warning message 
Bootstrap <- function(data, B, Statistic) {
  
  # Error and Warning message 
  if (typeof(data) == "character") {
      stop(" 'x' must be numeric")
  }
  
  # Code if everything is okay
  else {
    
    thêta_hat<- rep(0,B)
    thêta_star <- rep(0,B)
    
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
  }
}

```

In order to have this error message, I need to adapt my implementation by addition a section which will catch error on the type of the dataset I use for input. Indeed, I have use the function `stop` to have the error show and use a `if` to specify the typeof my input. 
Thus if the input isn't numeric the error will show. 
<br>
<br>

```{r, error=TRUE}
# Bootstrap(a, statistic = mean)
Bootstrap(data = a , B = 1000L, Statistic = mean)
```

5. Load `test2.rds` and execute `bootstrap(M, statistic = mean)`. The call must returns the following warning:
```{r echo = FALSE, include = FALSE, message = FALSE}
library(rstan)
test2 <- load("test2.rds")
typeof(test2)

call(test2)

```

```{r echo = FALSE, include = FALSE, message = FALSE}
# add to Error and Warning message
Bootstrap <- function(data, B, Statistic) {
  
  # Error and Warning message 
  if (typeof(data) == "double") {
    data <- as.vector(data)
    warning(" 'x' has been coerced to a vector ")
  }
  
  # Code if everything is okay
  
    thêta_hat<- rep(0,B)
    thêta_star <- rep(0,B)
    
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
  }
```

In order to have this warning message show, I need to adapt my implementation by addition a section which will catch changement which is apply on the input. Indeed the idea here is to treat `M`  as a vector, this modification is call coercion.
To do so I have use the function `warning` and modify my the data into a vector of dim NULL. 

Thus this message will occur and the code will continue to RUN. 

<br>
<br>
```{r, error=TRUE, results = 'hide'}
Bootstrap(M,B = 1000L, Statistic = mean)
```

6. Modify your implementation of `bootstrap` so `bootstrap(M, B="a", statistic = mean)` shows the following error: Error in bootstrap(M, B = "a", statistic = mean) : 'B' must be numeric

```{r echo = FALSE, include = FALSE, message = FALSE}

#Error in bootstrap(M, B = "a", statistic = mean) : 'B' must be numeric
# add to Error and Warning message 
Bootstrap <- function(data, B, Statistic) {
  
  # Error and Warning message 
  if (typeof(B) != "numeric") {
      stop(" 'B' must be numeric")
  }
  
  # Code if everything is okay
  else {
    thêta_hat <- rep(0,B)
    thêta_star <- rep(0,B)
  
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
  }
}
```

In order to have this error message, I need to adapt my implementation by addition a section which will catch error on the type of the dataset I use for input. Indeed, I have use the function `stop` to have the error show and use a `if` to specify the typeof B is not a numeric. 

Thus if the input isn't numeric the error will show. 
<br>
<br>

```{r, error=TRUE}
Bootstrap(M, B = "a", Statistic = mean)
```

7. Modify your implementation of `bootstrap` so `bootstrap(M, statistic = "mean")` shows the following error: Error in bootstrap(M, statistic = "mean"") : 'statistic' must be a function

In order to have this error message, I need to adapt the implementation of the statistic. Indeed, I have use the function `stop` to have the error show and use a `if` to specify the typeof statistic is not a function. To make easier i run the following condition: (Statistic != "var" | Statistic != "mean" ).

Thus if the statistic isn't a function the error will show. 
<br>
<br>

```{r echo = FALSE, include = FALSE, message = FALSE}
#Error in bootstrap(M, statistic = "mean"") : 'statistic' must be a function
#add to Error and Warning message section

Bootstrap <- function(data, B, Statistic) {
  
  # Error and Warning message 
  
  if (Statistic != "var" | Statistic != "mean" ) {
      stop(" 'statistic' must be a function")
  }
  
  # Code if everything is okay
  else {
    
    thêta_hat<- rep(0,B)
    thêta_star <- rep(0,B)
    
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
  }
}
```

```{r, error=TRUE}
Bootstrap(mydata, B = 1000L, Statistic = "mean")
```
8. Load `test3.rds` and see what happens when executing `bootstrap(m, statistic = mean)`. Remove any missing value from `m` and re-run the function calls. Removing missing values should happen within the function calls. The function `mean` has an argument for removing missing values, namely `mean(m, na.rm=TRUE)`. You are to exploit that, but `bootstrap(m, statistic = mean(na.rm = TRUE))` does not work (try it).  Modify your implementation by using `...` as an argument in order for `bootstrap(m, statistic = mean, na.rm = TRUE)` to return the expected results.

```{r echo = FALSE, include = FALSE, message = FALSE}
library(rstan)
test3 <- load("test3.rds")
typeof(test3)

call(test3)


```

```{r echo = FALSE, include = FALSE, message = FALSE}
Bootstrap <- function(data, B, Statistic, na.rm) {
  
  if (na.rm == TRUE) {
    na.omit(data)
  }
  
  # Code if everything is okay
  else {
    
    thêta_hat<- rep(0,B)
    thêta_star <- rep(0,B)
    
  if (Statistic == "var") {
    
     # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- var(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- var(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (var(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
  }
  
   if (Statistic == "mean") {
      # for the bootstrap estimate : list with the statistic evaluated on the sample x
  for (i in 1:B) {
  thêta_hat[i] <- mean(sample(data, replace = TRUE))                    
  }
  
   # for the bootstrap estimate : on the bootstrapped samples (on têta_hat)
  for (i in 1:B) {
  thêta_star[i] <- mean(sample(thêta_hat, replace = TRUE))                    
  }
  
  # for varBoot
  n <- as.numeric (length(thêta_hat))
  varBoot <- as.numeric (mean(thêta_hat) *  ((n - 1) / n))
  
  # for the output
  my_return <- list("thêta_hat" = thêta_hat, "theta_star" = thêta_star, "varBoot" = varBoot)
  return(my_return) 
   }
  }
}

```

After loading `test3.rds` , we can observe that there's a lot of NA. In order to remove them within the function calls. I have added another input which I named `na.rm` it will work as a dummy variable. If TRUE, then we will omit the NA, if it's FALSE we will include the NA in the calculation

<br>
<br>

```{r}
Bootstrap(m, B = 1000L, Statistic = mean, na.rm = TRUE)
```
### Problem 3
a)
```{r montecarlo, echo=FALSE}
f <- function(x) {
  return(exp(x) * log(x))
}

find_integral <- function(f, xlim, N = 1000, seed = 10, make_plot = FALSE){
  if (missingArg(f)) {
    f <- function(x) {exp(x) * log(x)}
  }
  if (missingArg(xlim)) {
    xlim <- c(0.1, 2)
  } else if (!is.numeric(xlim) || length(xlim) != 2) {
    stop('xlim is not properly defined')
  }
  # Control seed
  set.seed(seed)
  
  # Simulate N points
  U = runif(N, min = 0.1, max = 2)
  
  fi <- list()
  for (i in 1:length(U)){
    fi[i] = f(U[i])
  }
  
  I = 1.9 * (1/N) * sum(f(U))
  

  
  #plot(f(x), fi)
  
  integral_app <-   plot(f, type="l", col="blue", ylim=c(-3,5), xlim=c(0.1,2))
  lines(c(0,2.1), c(0,0), type="l", col="black")
  
  for (i in 1:length(U)){
  lines(c(U[i],U[i]), c(fi[i],0), type="l", pch=22, col="red")
  } 
  return(integral_app)
}

find_integral()



```
b)  
N = 10       gives: -0.6344028  
N = 100      gives:  0.2654028  
N = 1000     gives:  1.184418  
N = 10000    gives:  1.105195  
N = 100000   gives:  1.065235  
N = 1000000  gives:  1.083766  
N = 10000000 gives:  1.089825  
From the above results it can be concluded that increasing the N by tenfold will increase the accuracy of the approximation.  
  
### Problem 4 


#Separate the table into times when the observations are recoded and the states of the population Z_data.
```{r, echo=T}
# 1 )  load data
Z_data<-read.csv("sird_data.csv", header = TRUE)

#View(Z_data)

```

# 2) Initialize your "wild guess" of the parameters that you think are true
```{r}
params_0 <- c(
  beta = 0.7, # infection rate 
  gamma = 0.3,# recovery rate
  mu = 0.01) # mortality rate

```

# 3) initialize Z0 and times from 0-150 days
```{r}
Z_0 <- c(S=8756000,
I =44000,
R=0,
D=0)

N = Z_data$S[1] + Z_data$I[1] + Z_data$R[1] + Z_data$D[1]

time <- seq(0, 150, by = 1)
```

# 4) define function sird_model() that returns derivative over time of S(t), I(t), R(t), D(t)

````{r}
sird_model <- function(time, Z, par) {
  beta = par[1]
  gamma = par[2]
  mu = par[3]
  
  S = Z[1]
  I = Z[2]
  R = Z[3]
  D = Z[4]
  N = sum(Z)
  
  dS = -beta*S/N*I
  dI = beta*S/N*I - gamma*I - mu*I
  dR = gamma*I
  dD = mu*I
  
  return(list(c(dS, dI, dR, dD)))
}

````

#5 ) solve the model using ode() function to get the population dynamics over time with your "wild guess"ed parameters

````{r}
pt_5<-ode(y = Z_0, times = time, func = sird_model, parms = params_0)
#pt_5
PTS_55 <-melt(pt_5)
#PTS_55


ggplot(PTS_55)+
geom_line(aes(x=X1,y=value,colour =X2,group =X2))

# we can see that R and D are 0 compared to the data. 

#Compare the obtained solution with the given data.'''

`````

#6 ) It is time to find the best parameters that characterize the disease. Define the loss function as the sum of squared errors across all population groups

```{r}
loss <- function(parameters){
  names(parameters) <- c("beta", "gamma", "mu") # parameters must be named
  solution <- ode(y = Z_0, times = time, func = sird_model, parms = parameters) #fited
  S<- solution[, 2]
  I <- solution[, 3] # 3rd column of ODE solution
  R<- solution[, 4]
  D <- solution[, 5] # 5th column of ODE solution
  return(sum((I-Z_data$I)^2 + (D-Z_data$D)^2+(R-Z_data$R)^2+(S-Z_data$S)^2))
}
```


#7 minimze loss function with optim() function. Use method = "L-BFGS-B" and restrict parameters to be positive lower = 
```{r}
params_opt <- optim(par = params_0, fn = loss, method = "L-BFGS-B", lower = c(0,0,0), upper = c(1,1,1))
params_opt
```

#8) run ode (Z0,times,sird model,params_opt) and plot the zfit and Z_data

````{r}
Z_exo <- melt(Z_data) # melt Z_data better layout for plotting
Z_2<-Z_exo[152:nrow(Z_exo),] # remove t values

Zfit_1 <- ode(y = Z_0, times = time, func = sird_model, parms = c(0.199993809,0.049990838,0.001011214 ))  %>% melt()

Zfit_2<-Zfit_1[152:755,] # remove time


plot_final <- ggplot(Zfit_2)+
    geom_line(aes(x = X1, y = value, color =X2,group = X2),linetype = 'dotted')+ # model fitted
    geom_line(data = Z_2, aes(x = Zfit_2$X1, y = value, color = variable,group=variable),linetype = 'solid')+ #Z_data
    labs(x = "Time", y = "Population", title = "SIRD model + Z population")+
    theme(plot.title = element_text(hjust = 0.5))

plot_final
````

